ğŸ™ï¸ Speaker Diarization & Transcription Pipeline (Whisper + VAD)

An end-to-end Python pipeline for speaker diarization and speech transcription, designed to answer the question:

â€œWho spoke, when, and what was said?â€

This project processes raw audio files and produces speaker-labeled transcripts using modern speech processing techniques such as Voice Activity Detection (VAD), speaker embedding clustering, and OpenAI Whisper for transcription.


âœ¨ Key Features

âœ… Audio Preprocessing
Format conversion & resampling

Noise reduction & normalization

Filtering and denoising

âœ… Voice Activity Detection (VAD)
Accurate speech / silence segmentation
Powered by SpeechBrain

âœ… Speaker Diarization
Speaker embedding extraction
Clustering-based speaker segmentation
Detects who spoke when
Supports overlapping speech (configurable)

âœ… Speech Transcription
High-accuracy transcription using OpenAI Whisper
Multiple Whisper model sizes supported

âœ… Interactive UI 
Streamlit-based interface
Adjustable preprocessing & diarization parameters
Real-time transcription preview

ğŸ§  Typical Use Cases

ğŸ§ Meeting & interview transcription
ğŸ“ Call center audio analysis
ğŸ™ï¸ Podcast & panel discussion processing
ğŸ§ª Speech research & experimentation
ğŸ“Š Dataset preparation for speech ML models

ğŸ“ Project Structure
â”œâ”€â”€ app.py                     # Streamlit application
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ speaker_id_pipeline.ipynb   # Development & experiments
â”œâ”€â”€ audio_samples/             # Example input audio files
â”œâ”€â”€ output/                    # Transcripts & diarization output
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md

â–¶ï¸ Getting Started
1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Run the Streamlit App
streamlit run app.py


âš™ï¸ Configuration Highlights

ğŸ› Whisper model selection (tiny â†’ large)
ğŸ”Š Adjustable VAD sensitivity
ğŸ‘¥ Configurable speaker count range
âš¡ GPU acceleration enabled where available
ğŸ§© Modular pipeline for easy extension

ğŸ“¤ Output Example
[00:00:02 - 00:00:06] Speaker 1: Hello everyone, welcome to the meeting.
[00:00:07 - 00:00:12] Speaker 2: Thanks, letâ€™s get started.

Outputs include:
Speaker-labeled transcripts
Timestamps
Structured text ready for downstream processing


ğŸ› ï¸ Tech Stack & Keywords
Python
OpenAI Whisper
SpeechBrain
Speaker Diarization
Voice Activity Detection (VAD)
Audio Processing
ASR (Automatic Speech Recognition)
Clustering-based diarization
Streamlit
