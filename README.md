# ğŸ™ï¸ Speaker Identification and Transcription Pipeline

This project performs end-to-end audio processing, including:

- Audio preprocessing (conversion, filtering, normalization, denoising)
- Voice Activity Detection (VAD) using SpeechBrain
- Speaker Embedding extraction and clustering
- Speaker Diarization (who spoke when)
- Transcription using OpenAI's Whisper
- Optional Streamlit interface for interaction

## ğŸ“ Project Structure
```
â”œâ”€â”€ app.py                   # Streamlit app
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ speaker_id_pipeline.ipynb  # Development notebook
â”œâ”€â”€ audio_samples/          # Sample input audio (add your own)
â”œâ”€â”€ output/                 # Output files (ignored in .gitignore)
â”œâ”€â”€ models/                 # Pretrained models (ignored)
â”œâ”€â”€ tests/                  # Test scripts (optional)
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .gitignore              # Ignored files/folders
â””â”€â”€ README.md
```

## â–¶ï¸ Run the App
```bash
pip install -r requirements.txt
streamlit run app.py
```

## ğŸ“Œ Notes
- Whisper model selection is available in the sidebar.
- All processing is GPU-accelerated where possible.
- Preprocessing options and speaker range are customizable.